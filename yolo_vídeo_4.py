# -*- coding: utf-8 -*-
"""YOLO vídeo 4

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LGPdBjUW_1tMaq_F7n2Lg2UPRrFbDtvF

# YOLO - Treinamento customizado

O conjunto de imagens customizado para fazer o treinamento com a ferramenta YOLO precisa de:

* Imagens das classes para detecção, já catalogadas (com os arquivos annotation)


> * Dataset ou repositório como o Open Images Dataset (Google).
*[OIDv4 Toolkit](https://github.com/EscVM/OIDv4_ToolKit)
* Baixar manualmente as imagens do objeto e catalogá-las utilizando alguma ferramenta de anotação (annotation tool) para obter os txt com as anotações.


* Arquivos obj.data e obj.names 
* Arquivo .cfg customizado
* Arquivo train.txt (test.txt é opcional)

# Coleta e catalogação das imagens dos objetos para treinamento

## Etapa 1 - Clonando o repositório da ferramenta
"""

!git clone https://github.com/EscVM/OIDv4_ToolKit.git

"""## Etapa 2 - Acessando o diretório da ferramenta """

ls

cd OIDv4_ToolKit/

ls

"""## Etapa 3 - Instalando todas as bibliotecas necessárias"""

!pip3 install -r requirements.txt

"""## Etapa 4 - Fazendo o download das imagens

### Conjunto de imagens de Treinamento
"""

!python main.py downloader --classes Bird Butterfly Flower --type_csv train --limit 500 --multiclasses 1

"""### Conjunto de imagens de Validação"""

!python main.py downloader --classes Bird Butterfly Flower --type_csv test --limit 100 --multiclasses 1

"""## Etapa 5 - Convertendo os arquivos de anotação

### 1. Colocar as classes no arquivo classes.txt
"""

!cat classes.txt

!echo -e 'Bird\nButterfly\nFlower' > classes.txt

"""### 2. Clonando o Repositório da Ferramenta"""

!git clone -n https://github.com/Hemilibeatriz/TreinamentoCustomizadoYOLO.git

cd TreinamentoCustomizadoYOLO/

ls

!git checkout HEAD converter_anotacoes.py

!mv converter_anotacoes.py /content/OIDv4_ToolKit/

ls

cd ..

"""### 3. Executar o Arquivo de Conversão"""

!python converter_anotacoes.py

"""## Etapa 6 - Compactar o Dataset"""

cd OID/Dataset/train/

!zip -r ../../../obj.zip obj -x obj/Label/*

ls

cd ..

cd test/

ls

!zip -r ../../../valid.zip valid -x valid/Label/*

from google.colab import drive
drive.mount('/content/gdrive')

ls

cd ../../../

!cp ./obj.zip /content/gdrive/My\ Drive/TreinamentoCustomizadoYOLO

!cp ./valid.zip /content/gdrive/My\ Drive/TreinamentoCustomizadoYOLO

"""# Edição dos arquivos de configuração"""

cd ..

!git clone https://github.com/AlexeyAB/darknet

cd darknet/

!make

"""## Etapa 7 - Arquivos a serem editados

### Modificações no .cfg
"""

!cp cfg/yolov4.cfg /content/gdrive/My\ Drive/TreinamentoCustomizadoYOLO/yolov4_custom.cfg

"""### Modificações no obj.names e obj.data"""

!touch obj.names
!touch obj.data

!cp obj.names /content/gdrive/My\ Drive/TreinamentoCustomizadoYOLO/obj.names
!cp obj.data /content/gdrive/My\ Drive/TreinamentoCustomizadoYOLO/obj.data

"""## Etapa 8 - Gerando o arquivo train.txt e test.txt"""

cd ..

cd OIDv4_ToolKit/

!unzip obj.zip -d ./data

!unzip valid.zip -d ./data

cd TreinamentoCustomizadoYOLO/

!git checkout HEAD gera_train.py

!git checkout HEAD gera_test.py

!mv gera_train.py /content/OIDv4_ToolKit/

!mv gera_test.py /content/OIDv4_ToolKit/

cd ..

!python /content/OIDv4_ToolKit/gera_train.py

!python /content/OIDv4_ToolKit/gera_test.py

cd data

!cp train.txt /content/gdrive/My\ Drive/TreinamentoCustomizadoYOLO/train.txt

!cp test.txt /content/gdrive/My\ Drive/TreinamentoCustomizadoYOLO/test.txt

"""# YOLO - Treinamento"""

import tensorflow as tf
device_name = tf.test.gpu_device_name()
print(device_name)

"""## Etapa 1 - Conectando ao Google Drive"""

from google.colab import drive
drive.mount('/content/gdrive')

"""### Abreviando o caminho para o Google Drive"""

!ln -s /content/gdrive/My\ Drive/TreinamentoCustomizadoYOLO/ /TreinamentoCustomizadoYOLO

!ls /content/gdrive/My\ Drive/TreinamentoCustomizadoYOLO/

ls /TreinamentoCustomizadoYOLO/

"""## Etapa 2 - Clone do Darknet"""

!git clone https://github.com/AlexeyAB/darknet

cd darknet

ls

"""## Etapa 3 - Compilando a Biblioteca"""

!sed -i 's/OPENCV=0/OPENCV=1/' Makefile
!sed -i 's/GPU=0/GPU=1/' Makefile
!sed -i 's/CUDNN=0/CUDNN=1/' Makefile

!make

"""## Etapa 4 - Enviando o DataSet Customizado

### Copiando o conjunto de imagens de treinamento e validação
"""

ls /TreinamentoCustomizadoYOLO/

!unzip /TreinamentoCustomizadoYOLO/obj.zip -d ./data/

!unzip /TreinamentoCustomizadoYOLO/valid.zip -d ./data/

"""### Copiando os arquivos de configuração """

!cp /TreinamentoCustomizadoYOLO/yolov4_custom.cfg ./cfg
!cp /TreinamentoCustomizadoYOLO/obj.names ./data
!cp /TreinamentoCustomizadoYOLO/obj.data ./data
!cp /TreinamentoCustomizadoYOLO/train.txt ./data
!cp /TreinamentoCustomizadoYOLO/test.txt ./data

"""## Etapa 5 - Baixando os pesos pré-treinados das camadas convolucionais






"""

!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137

"""## Etapa 6 - Treinamento do Modelo 






"""

!./darknet detector train data/obj.data cfg/yolov4_custom.cfg yolov4.conv.137 -dont_show -map

"""## Etapa 7 - Visualizar o chart.png






"""

import cv2
import matplotlib.pyplot as plt

def mostrar(caminho):
  img = cv2.imread(caminho)
  fig = plt.gcf()
  fig.set_size_inches(18, 10)
  plt.axis("off")
  plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
  plt.show()

mostrar('chart.png')

"""# Continuando o treinamento"""

!./darknet detector train data/obj.data cfg/yolov4_custom.cfg /TreinamentoCustomizadoYOLO/yolov4_custom_last.weights -dont_show -map

"""# Verificando o mAP (Mean Average Precision) do modelo """

!./darknet detector map data/obj.data cfg/yolov4_custom.cfg /TreinamentoCustomizadoYOLO/yolov4_custom_last.weights

"""# Testando o modelo treinado"""

!./darknet detector test data/obj.data cfg/yolov4_custom.cfg /TreinamentoCustomizadoYOLO/yolov4_custom_last.weights /TreinamentoCustomizadoYOLO/imagem.jpg -thresh 0.005

mostrar('predictions.jpg')